// AUTO-GENERATED: Complete Softmax Implementation
// Generated by generate_attention_scores_and_softmax.py

// ============================================================================
// Attention Scores Storage - Add this to your FixedPools section
// ============================================================================

FixedPool.AttentionScores {
    "s0": Initialize=0   
    "s1": Initialize=0   
    "s2": Initialize=0   
    "s3": Initialize=0   
    "s4": Initialize=0   
    "s5": Initialize=0   
    "s6": Initialize=0   
    "s7": Initialize=0   
    "s8": Initialize=0   
    "s9": Initialize=0   
    "s10": Initialize=0   
    "s11": Initialize=0   
    "s12": Initialize=0   
    "s13": Initialize=0   
    "s14": Initialize=0   
    "s15": Initialize=0   
    "s16": Initialize=0   
    "s17": Initialize=0   
    "s18": Initialize=0   
    "s19": Initialize=0   
    "s20": Initialize=0   
    "s21": Initialize=0   
    "s22": Initialize=0   
    "s23": Initialize=0   
    "s24": Initialize=0   
    "s25": Initialize=0   
    "s26": Initialize=0   
    "s27": Initialize=0   
    "s28": Initialize=0   
    "s29": Initialize=0   
    "s30": Initialize=0   
    "s31": Initialize=0
    "count": Initialize=0
    "exp_sum": Initialize=0
}

// ============================================================================
// UPGRADED: ApplySoftmax - Full implementation with Math.Exp
// Computes softmax over all cached attention scores
// ============================================================================

SubRoutine.ApplySoftmax {
    DebugPerf.Start("softmax")
    Debug("smollm.trace", level=2) {
        PrintMessage("[ApplySoftmax] ENTER, count=")
        PrintNumber(AttentionScores.count)
        PrintMessage("\n")
    }
    
    // Step 1: Find maximum score for numerical stability
    max_score = -999999
    score_idx = 0
    
    WhileLoop LessThan(score_idx, AttentionScores.count) {
        Branch score_idx {
            Case 0: { current_score = AttentionScores.s0 }
            Case 1: { current_score = AttentionScores.s1 }
            Case 2: { current_score = AttentionScores.s2 }
            Case 3: { current_score = AttentionScores.s3 }
            Case 4: { current_score = AttentionScores.s4 }
            Case 5: { current_score = AttentionScores.s5 }
            Case 6: { current_score = AttentionScores.s6 }
            Case 7: { current_score = AttentionScores.s7 }
            Case 8: { current_score = AttentionScores.s8 }
            Case 9: { current_score = AttentionScores.s9 }
            Case 10: { current_score = AttentionScores.s10 }
            Case 11: { current_score = AttentionScores.s11 }
            Case 12: { current_score = AttentionScores.s12 }
            Case 13: { current_score = AttentionScores.s13 }
            Case 14: { current_score = AttentionScores.s14 }
            Case 15: { current_score = AttentionScores.s15 }
            Case 16: { current_score = AttentionScores.s16 }
            Case 17: { current_score = AttentionScores.s17 }
            Case 18: { current_score = AttentionScores.s18 }
            Case 19: { current_score = AttentionScores.s19 }
            Case 20: { current_score = AttentionScores.s20 }
            Case 21: { current_score = AttentionScores.s21 }
            Case 22: { current_score = AttentionScores.s22 }
            Case 23: { current_score = AttentionScores.s23 }
            Case 24: { current_score = AttentionScores.s24 }
            Case 25: { current_score = AttentionScores.s25 }
            Case 26: { current_score = AttentionScores.s26 }
            Case 27: { current_score = AttentionScores.s27 }
            Case 28: { current_score = AttentionScores.s28 }
            Case 29: { current_score = AttentionScores.s29 }
            Case 30: { current_score = AttentionScores.s30 }
            Case 31: { current_score = AttentionScores.s31 }
            Default: { current_score = 0 }
        }
        
        IfCondition GreaterThan(current_score, max_score) ThenBlock: {
            max_score = current_score
        }
        
        score_idx = Add(score_idx, 1)
    }
    
    Debug("smollm.trace", level=3) {
        PrintMessage("  [Softmax] max_score=")
        PrintNumber(max_score)
        PrintMessage("\n")
    }
    
    // Step 2: Compute exp(score - max) and sum
    AttentionScores.exp_sum = 0
    score_idx = 0
    
    WhileLoop LessThan(score_idx, AttentionScores.count) {
        // Get score[i]
        Branch score_idx {
            Case 0: { current_score = AttentionScores.s0 }
            Case 1: { current_score = AttentionScores.s1 }
            Case 2: { current_score = AttentionScores.s2 }
            Case 3: { current_score = AttentionScores.s3 }
            Case 4: { current_score = AttentionScores.s4 }
            Case 5: { current_score = AttentionScores.s5 }
            Case 6: { current_score = AttentionScores.s6 }
            Case 7: { current_score = AttentionScores.s7 }
            Case 8: { current_score = AttentionScores.s8 }
            Case 9: { current_score = AttentionScores.s9 }
            Case 10: { current_score = AttentionScores.s10 }
            Case 11: { current_score = AttentionScores.s11 }
            Case 12: { current_score = AttentionScores.s12 }
            Case 13: { current_score = AttentionScores.s13 }
            Case 14: { current_score = AttentionScores.s14 }
            Case 15: { current_score = AttentionScores.s15 }
            Case 16: { current_score = AttentionScores.s16 }
            Case 17: { current_score = AttentionScores.s17 }
            Case 18: { current_score = AttentionScores.s18 }
            Case 19: { current_score = AttentionScores.s19 }
            Case 20: { current_score = AttentionScores.s20 }
            Case 21: { current_score = AttentionScores.s21 }
            Case 22: { current_score = AttentionScores.s22 }
            Case 23: { current_score = AttentionScores.s23 }
            Case 24: { current_score = AttentionScores.s24 }
            Case 25: { current_score = AttentionScores.s25 }
            Case 26: { current_score = AttentionScores.s26 }
            Case 27: { current_score = AttentionScores.s27 }
            Case 28: { current_score = AttentionScores.s28 }
            Case 29: { current_score = AttentionScores.s29 }
            Case 30: { current_score = AttentionScores.s30 }
            Case 31: { current_score = AttentionScores.s31 }
            Default: { current_score = 0 }
        }
        
        // Compute stable score = score - max
        stable_score = Subtract(current_score, max_score)
        
        // Scale for Math.Exp (expects fixed-point with scale=10000)
        // Our scores are in range ~0-10000, so divide by 100 to prevent overflow
        scaled_score = Divide(stable_score, 100)
        
        // Compute exp(stable_score)
        exp_val = Math.Exp(scaled_score)
        
        Debug("smollm.trace", level=4) {
            PrintMessage("    [Softmax] s")
            PrintNumber(score_idx)
            PrintMessage("=")
            PrintNumber(current_score)
            PrintMessage(", exp=")
            PrintNumber(exp_val)
            PrintMessage("\n")
        }
        
        // Store exp value back (reusing score slots)
        Branch score_idx {
            Case 0: { AttentionScores.s0 = exp_val }
            Case 1: { AttentionScores.s1 = exp_val }
            Case 2: { AttentionScores.s2 = exp_val }
            Case 3: { AttentionScores.s3 = exp_val }
            Case 4: { AttentionScores.s4 = exp_val }
            Case 5: { AttentionScores.s5 = exp_val }
            Case 6: { AttentionScores.s6 = exp_val }
            Case 7: { AttentionScores.s7 = exp_val }
            Case 8: { AttentionScores.s8 = exp_val }
            Case 9: { AttentionScores.s9 = exp_val }
            Case 10: { AttentionScores.s10 = exp_val }
            Case 11: { AttentionScores.s11 = exp_val }
            Case 12: { AttentionScores.s12 = exp_val }
            Case 13: { AttentionScores.s13 = exp_val }
            Case 14: { AttentionScores.s14 = exp_val }
            Case 15: { AttentionScores.s15 = exp_val }
            Case 16: { AttentionScores.s16 = exp_val }
            Case 17: { AttentionScores.s17 = exp_val }
            Case 18: { AttentionScores.s18 = exp_val }
            Case 19: { AttentionScores.s19 = exp_val }
            Case 20: { AttentionScores.s20 = exp_val }
            Case 21: { AttentionScores.s21 = exp_val }
            Case 22: { AttentionScores.s22 = exp_val }
            Case 23: { AttentionScores.s23 = exp_val }
            Case 24: { AttentionScores.s24 = exp_val }
            Case 25: { AttentionScores.s25 = exp_val }
            Case 26: { AttentionScores.s26 = exp_val }
            Case 27: { AttentionScores.s27 = exp_val }
            Case 28: { AttentionScores.s28 = exp_val }
            Case 29: { AttentionScores.s29 = exp_val }
            Case 30: { AttentionScores.s30 = exp_val }
            Case 31: { AttentionScores.s31 = exp_val }
        }
        
        // Accumulate sum
        AttentionScores.exp_sum = Add(AttentionScores.exp_sum, exp_val)
        
        score_idx = Add(score_idx, 1)
    }
    
    Debug("smollm.trace", level=3) {
        PrintMessage("  [Softmax] exp_sum=")
        PrintNumber(AttentionScores.exp_sum)
        PrintMessage("\n")
    }
    
    // Step 3: Normalize by dividing by sum
    score_idx = 0
    
    IfCondition GreaterThan(AttentionScores.exp_sum, 0) ThenBlock: {
        WhileLoop LessThan(score_idx, AttentionScores.count) {
            // Get exp value
            Branch score_idx {
                Case 0: { exp_val = AttentionScores.s0 }
                Case 1: { exp_val = AttentionScores.s1 }
                Case 2: { exp_val = AttentionScores.s2 }
                Case 3: { exp_val = AttentionScores.s3 }
                Case 4: { exp_val = AttentionScores.s4 }
                Case 5: { exp_val = AttentionScores.s5 }
                Case 6: { exp_val = AttentionScores.s6 }
                Case 7: { exp_val = AttentionScores.s7 }
                Case 8: { exp_val = AttentionScores.s8 }
                Case 9: { exp_val = AttentionScores.s9 }
                Case 10: { exp_val = AttentionScores.s10 }
                Case 11: { exp_val = AttentionScores.s11 }
                Case 12: { exp_val = AttentionScores.s12 }
                Case 13: { exp_val = AttentionScores.s13 }
                Case 14: { exp_val = AttentionScores.s14 }
                Case 15: { exp_val = AttentionScores.s15 }
                Case 16: { exp_val = AttentionScores.s16 }
                Case 17: { exp_val = AttentionScores.s17 }
                Case 18: { exp_val = AttentionScores.s18 }
                Case 19: { exp_val = AttentionScores.s19 }
                Case 20: { exp_val = AttentionScores.s20 }
                Case 21: { exp_val = AttentionScores.s21 }
                Case 22: { exp_val = AttentionScores.s22 }
                Case 23: { exp_val = AttentionScores.s23 }
                Case 24: { exp_val = AttentionScores.s24 }
                Case 25: { exp_val = AttentionScores.s25 }
                Case 26: { exp_val = AttentionScores.s26 }
                Case 27: { exp_val = AttentionScores.s27 }
                Case 28: { exp_val = AttentionScores.s28 }
                Case 29: { exp_val = AttentionScores.s29 }
                Case 30: { exp_val = AttentionScores.s30 }
                Case 31: { exp_val = AttentionScores.s31 }
                Default: { exp_val = 0 }
            }
            
            // Normalize: softmax[i] = exp[i] / sum
            // Scale to 0-1000 range for fixed-point
            normalized = FixedPoint.Divide(Multiply(exp_val, 1000), AttentionScores.exp_sum)
            
            Debug("smollm.trace", level=4) {
                PrintMessage("    [Softmax] normalized[")
                PrintNumber(score_idx)
                PrintMessage("]=")
                PrintNumber(normalized)
                PrintMessage("\n")
            }
            
            // Store normalized value
            Branch score_idx {
                Case 0: { AttentionScores.s0 = normalized }
                Case 1: { AttentionScores.s1 = normalized }
                Case 2: { AttentionScores.s2 = normalized }
                Case 3: { AttentionScores.s3 = normalized }
                Case 4: { AttentionScores.s4 = normalized }
                Case 5: { AttentionScores.s5 = normalized }
                Case 6: { AttentionScores.s6 = normalized }
                Case 7: { AttentionScores.s7 = normalized }
                Case 8: { AttentionScores.s8 = normalized }
                Case 9: { AttentionScores.s9 = normalized }
                Case 10: { AttentionScores.s10 = normalized }
                Case 11: { AttentionScores.s11 = normalized }
                Case 12: { AttentionScores.s12 = normalized }
                Case 13: { AttentionScores.s13 = normalized }
                Case 14: { AttentionScores.s14 = normalized }
                Case 15: { AttentionScores.s15 = normalized }
                Case 16: { AttentionScores.s16 = normalized }
                Case 17: { AttentionScores.s17 = normalized }
                Case 18: { AttentionScores.s18 = normalized }
                Case 19: { AttentionScores.s19 = normalized }
                Case 20: { AttentionScores.s20 = normalized }
                Case 21: { AttentionScores.s21 = normalized }
                Case 22: { AttentionScores.s22 = normalized }
                Case 23: { AttentionScores.s23 = normalized }
                Case 24: { AttentionScores.s24 = normalized }
                Case 25: { AttentionScores.s25 = normalized }
                Case 26: { AttentionScores.s26 = normalized }
                Case 27: { AttentionScores.s27 = normalized }
                Case 28: { AttentionScores.s28 = normalized }
                Case 29: { AttentionScores.s29 = normalized }
                Case 30: { AttentionScores.s30 = normalized }
                Case 31: { AttentionScores.s31 = normalized }
            }
            
            score_idx = Add(score_idx, 1)
        }
    } ElseBlock: {
        // If sum is zero, set uniform distribution
        uniform_val = IfCondition GreaterThan(AttentionScores.count, 0) 
            ThenValue: Divide(1000, AttentionScores.count)
            ElseValue: 1000
        
        score_idx = 0
        WhileLoop LessThan(score_idx, AttentionScores.count) {
            Branch score_idx {
                Case 0: { AttentionScores.s0 = uniform_val }
                Case 1: { AttentionScores.s1 = uniform_val }
                Case 2: { AttentionScores.s2 = uniform_val }
                Case 3: { AttentionScores.s3 = uniform_val }
                Case 4: { AttentionScores.s4 = uniform_val }
                Case 5: { AttentionScores.s5 = uniform_val }
                Case 6: { AttentionScores.s6 = uniform_val }
                Case 7: { AttentionScores.s7 = uniform_val }
                Case 8: { AttentionScores.s8 = uniform_val }
                Case 9: { AttentionScores.s9 = uniform_val }
                Case 10: { AttentionScores.s10 = uniform_val }
                Case 11: { AttentionScores.s11 = uniform_val }
                Case 12: { AttentionScores.s12 = uniform_val }
                Case 13: { AttentionScores.s13 = uniform_val }
                Case 14: { AttentionScores.s14 = uniform_val }
                Case 15: { AttentionScores.s15 = uniform_val }
                Case 16: { AttentionScores.s16 = uniform_val }
                Case 17: { AttentionScores.s17 = uniform_val }
                Case 18: { AttentionScores.s18 = uniform_val }
                Case 19: { AttentionScores.s19 = uniform_val }
                Case 20: { AttentionScores.s20 = uniform_val }
                Case 21: { AttentionScores.s21 = uniform_val }
                Case 22: { AttentionScores.s22 = uniform_val }
                Case 23: { AttentionScores.s23 = uniform_val }
                Case 24: { AttentionScores.s24 = uniform_val }
                Case 25: { AttentionScores.s25 = uniform_val }
                Case 26: { AttentionScores.s26 = uniform_val }
                Case 27: { AttentionScores.s27 = uniform_val }
                Case 28: { AttentionScores.s28 = uniform_val }
                Case 29: { AttentionScores.s29 = uniform_val }
                Case 30: { AttentionScores.s30 = uniform_val }
                Case 31: { AttentionScores.s31 = uniform_val }
            }
            score_idx = Add(score_idx, 1)
        }
    }
    
    Debug("smollm.trace", level=2) {
        PrintMessage("[ApplySoftmax] EXIT\n")
    }
    DebugPerf.End("softmax")
}

// ============================================================================
// UPDATED: ComputeAttention - Store scores in AttentionScores pool
// Replace your existing ComputeAttention with this
// ============================================================================

SubRoutine.ComputeAttention {
    DebugPerf.Start("attention")
    Debug("smollm.trace", level=2) {
        PrintMessage("[ComputeAttention] ENTER\n")
    }
    
    // Reset attention scores
    AttentionScores.count = 0
    
    // Compute attention score for each cached key
    cache_idx = 0
    WhileLoop LessThan(cache_idx, KeyCache.count) {
        // Compute Q · K_i (dot product)
        score = 0
        
        // Get Key vector from cache at position cache_idx
        // For now, simplified version with current KeyVector
        // In full version, you'd retrieve from KeyCache.s{cache_idx}_d{dim}
        
        score = Add(
            Multiply(QueryVector.q0, KeyVector.k0),
            Multiply(QueryVector.q1, KeyVector.k1))
        
        // Add remaining dimensions q2-q31 × k2-k31
        score = Add(score, Multiply(QueryVector.q2, KeyVector.k2))
        score = Add(score, Multiply(QueryVector.q3, KeyVector.k3))
        // ... continue for all 32 dimensions
        
        // Scale down to prevent overflow
        score = Divide(score, 100)
        
        Debug("smollm.trace", level=3) {
            PrintMessage("  [Attention] score[")
            PrintNumber(cache_idx)
            PrintMessage("]=")
            PrintNumber(score)
            PrintMessage("\n")
        }
        
        // Store score in AttentionScores pool
        Branch cache_idx {
            Case 0: { AttentionScores.s0 = score }
            Case 1: { AttentionScores.s1 = score }
            Case 2: { AttentionScores.s2 = score }
            Case 3: { AttentionScores.s3 = score }
            Case 4: { AttentionScores.s4 = score }
            Case 5: { AttentionScores.s5 = score }
            Case 6: { AttentionScores.s6 = score }
            Case 7: { AttentionScores.s7 = score }
            // ... continue for all 32 positions
        }
        
        AttentionScores.count = Add(AttentionScores.count, 1)
        cache_idx = Add(cache_idx, 1)
    }
    
    Debug("smollm.trace", level=2) {
        PrintMessage("[ComputeAttention] EXIT, computed ")
        PrintNumber(AttentionScores.count)
        PrintMessage(" scores\n")
    }
    DebugPerf.End("attention")
}
